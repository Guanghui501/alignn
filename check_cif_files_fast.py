#!/usr/bin/env python
"""
å¤šçº¿ç¨‹ CIF æ–‡ä»¶æ£€æŸ¥å·¥å…·
ä½¿ç”¨å¤šçº¿ç¨‹å¤§å¹…åŠ é€Ÿæ–‡ä»¶æ£€æŸ¥è¿‡ç¨‹
"""
import os
import sys
import glob
import pandas as pd
from pathlib import Path
import shutil
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from multiprocessing import cpu_count
import argparse

def check_single_cif(cif_file):
    """
    æ£€æŸ¥å•ä¸ª CIF æ–‡ä»¶
    è¿”å›: (file_path, is_good, error_message)
    """
    try:
        from jarvis.core.atoms import Atoms
        atoms = Atoms.from_cif(cif_file)

        # æ£€æŸ¥æ˜¯å¦æœ‰åŸå­
        if len(atoms.cart_coords) == 0:
            return (cif_file, False, "æ²¡æœ‰åŸå­åæ ‡")
        else:
            return (cif_file, True, None)
    except Exception as e:
        error_msg = str(e)[:100]
        return (cif_file, False, error_msg)


def check_cif_files_parallel(data_dir, num_workers=None, remove_bad=False):
    """
    å¹¶è¡Œæ£€æŸ¥æ‰€æœ‰ CIF æ–‡ä»¶

    Args:
        data_dir: æ•°æ®ç›®å½•
        num_workers: çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°
        remove_bad: æ˜¯å¦è‡ªåŠ¨ç§»åŠ¨é—®é¢˜æ–‡ä»¶
    """

    print("=" * 70)
    print("CIF æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥å·¥å…·ï¼ˆå¤šçº¿ç¨‹åŠ é€Ÿç‰ˆï¼‰")
    print("=" * 70)
    print(f"\næ•°æ®ç›®å½•: {data_dir}")

    # ç¡®å®šçº¿ç¨‹æ•°
    if num_workers is None:
        num_workers = cpu_count()

    print(f"ä½¿ç”¨çº¿ç¨‹æ•°: {num_workers}")
    print()

    # æŸ¥æ‰¾æ‰€æœ‰ CIF æ–‡ä»¶
    print("æ­¥éª¤1: æœç´¢ CIF æ–‡ä»¶...")
    cif_files = glob.glob(os.path.join(data_dir, "*.cif"))

    if len(cif_files) == 0:
        print(f"âŒ é”™è¯¯: åœ¨ {data_dir} ä¸­æ²¡æœ‰æ‰¾åˆ° CIF æ–‡ä»¶")
        return False

    print(f"âœ“ æ‰¾åˆ° {len(cif_files)} ä¸ª CIF æ–‡ä»¶\n")

    # å¤šçº¿ç¨‹æ£€æŸ¥
    print("æ­¥éª¤2: å¹¶è¡Œæ£€æŸ¥æ‰€æœ‰ CIF æ–‡ä»¶...")
    print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\n")

    good_files = []
    bad_files = []

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {executor.submit(check_single_cif, f): f for f in cif_files}

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        with tqdm(total=len(cif_files), desc="æ£€æŸ¥è¿›åº¦") as pbar:
            for future in as_completed(futures):
                file_path, is_good, error_msg = future.result()

                if is_good:
                    good_files.append(file_path)
                else:
                    bad_files.append((file_path, error_msg))

                pbar.update(1)

    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 70)
    print("æ£€æŸ¥ç»“æœ")
    print("=" * 70)
    total = len(cif_files)
    good_pct = len(good_files) / total * 100
    bad_pct = len(bad_files) / total * 100

    print(f"âœ“ å¯è¯»å–çš„æ–‡ä»¶: {len(good_files)} ({good_pct:.1f}%)")
    print(f"âœ— æ— æ³•è¯»å–çš„æ–‡ä»¶: {len(bad_files)} ({bad_pct:.1f}%)")

    if len(bad_files) > 0:
        print(f"\næ— æ³•è¯»å–çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰:")
        print("-" * 70)
        for i, (fpath, error) in enumerate(sorted(bad_files)[:20], 1):
            fname = os.path.basename(fpath)
            print(f"{i:3d}. {fname:30s} | {error}")

        if len(bad_files) > 20:
            print(f"     ... è¿˜æœ‰ {len(bad_files)-20} ä¸ªæ–‡ä»¶")

        # ä¿å­˜å®Œæ•´çš„é—®é¢˜æ–‡ä»¶åˆ—è¡¨
        bad_list_file = os.path.join(data_dir, "bad_cif_files.txt")
        with open(bad_list_file, 'w') as f:
            f.write("# æ— æ³•è¯»å–çš„ CIF æ–‡ä»¶åˆ—è¡¨\n")
            f.write(f"# æ€»è®¡: {len(bad_files)} ä¸ªæ–‡ä»¶\n")
            f.write(f"# æ£€æŸ¥æ—¶é—´: {pd.Timestamp.now()}\n\n")
            for fpath, error in sorted(bad_files):
                fname = os.path.basename(fpath)
                f.write(f"{fname}\t{error}\n")

        print(f"\nå®Œæ•´åˆ—è¡¨å·²ä¿å­˜åˆ°: {bad_list_file}")

        # è¯¢é—®æ˜¯å¦å¤„ç†é—®é¢˜æ–‡ä»¶
        if remove_bad:
            action = 'move'
        else:
            print("\n" + "=" * 70)
            print("å¤„ç†é€‰é¡¹:")
            print("=" * 70)
            print("1. ç§»åŠ¨åˆ°å•ç‹¬çš„ç›®å½• (æ¨è) - ä¿ç•™æ–‡ä»¶ä½†ä¸å‚ä¸è®­ç»ƒ")
            print("2. åˆ é™¤è¿™äº›æ–‡ä»¶ - æ°¸ä¹…åˆ é™¤")
            print("3. ä¿ç•™ä¸å¤„ç† - è®­ç»ƒæ—¶å¯èƒ½ä¼šå‡ºé”™")
            print()
            choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()

            if choice == '1':
                action = 'move'
            elif choice == '2':
                action = 'delete'
            else:
                action = 'keep'
                print("\nâš ï¸  ä¿ç•™é—®é¢˜æ–‡ä»¶ï¼Œè®­ç»ƒæ—¶å¯èƒ½ä¼šé‡åˆ°é”™è¯¯")

        if action == 'move':
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            bad_dir = os.path.join(data_dir, "bad_cif_files")
            os.makedirs(bad_dir, exist_ok=True)

            print(f"\nç§»åŠ¨é—®é¢˜æ–‡ä»¶åˆ°: {bad_dir}")
            for fpath, _ in tqdm(bad_files, desc="ç§»åŠ¨è¿›åº¦"):
                fname = os.path.basename(fpath)
                dest = os.path.join(bad_dir, fname)
                shutil.move(fpath, dest)

            print(f"âœ“ å·²ç§»åŠ¨ {len(bad_files)} ä¸ªæ–‡ä»¶")

        elif action == 'delete':
            confirm = input(f"\nâš ï¸  ç¡®è®¤åˆ é™¤ {len(bad_files)} ä¸ªæ–‡ä»¶? (yes/no): ").strip().lower()
            if confirm == 'yes':
                print("\nåˆ é™¤é—®é¢˜æ–‡ä»¶...")
                for fpath, _ in tqdm(bad_files, desc="åˆ é™¤è¿›åº¦"):
                    os.remove(fpath)
                print(f"âœ“ å·²åˆ é™¤ {len(bad_files)} ä¸ªæ–‡ä»¶")
            else:
                print("å–æ¶ˆåˆ é™¤")
                action = 'keep'

        # å¦‚æœç§»åŠ¨æˆ–åˆ é™¤äº†æ–‡ä»¶ï¼Œéœ€è¦æ›´æ–° id_prop.csv
        if action in ['move', 'delete']:
            print("\næ­¥éª¤3: æ›´æ–° id_prop.csv...")

            # è¯»å– id_prop.csv
            csv_path = os.path.join(data_dir, "id_prop.csv")
            if os.path.exists(csv_path):
                # å¤‡ä»½
                backup_path = csv_path + ".backup_cif_check"
                if not os.path.exists(backup_path):
                    shutil.copy(csv_path, backup_path)
                    print(f"  âœ“ å·²å¤‡ä»½åˆ°: {backup_path}")

                # è¯»å– CSV
                try:
                    # å°è¯•ä¸åŒçš„è¯»å–æ–¹å¼
                    try:
                        df = pd.read_csv(csv_path)
                    except:
                        df = pd.read_csv(csv_path, header=None)
                        if len(df.columns) == 2:
                            df.columns = ['id', 'target']

                    # è·å–è¦ç§»é™¤çš„æ–‡ä»¶ID
                    bad_ids = set()
                    for fpath, _ in bad_files:
                        fname = os.path.basename(fpath)
                        # ç§»é™¤ .cif åç¼€
                        file_id = fname.replace('.cif', '')
                        bad_ids.add(file_id)

                    # è¿‡æ»¤DataFrame
                    original_len = len(df)

                    # å¤„ç†idåˆ—ï¼Œç§»é™¤å¯èƒ½çš„ .cif åç¼€
                    if 'id' in df.columns:
                        id_col = 'id'
                    else:
                        id_col = df.columns[0]

                    df[id_col] = df[id_col].astype(str).str.replace('.cif', '')
                    df_clean = df[~df[id_col].isin(bad_ids)]

                    # ä¿å­˜
                    df_clean.to_csv(csv_path, index=False, header=True)

                    removed_count = original_len - len(df_clean)
                    print(f"  âœ“ å·²ä» id_prop.csv ç§»é™¤ {removed_count} æ¡è®°å½•")
                    print(f"  å‰©ä½™: {len(df_clean)} æ¡è®°å½•")

                except Exception as e:
                    print(f"  âš ï¸  è­¦å‘Š: æ— æ³•è‡ªåŠ¨æ›´æ–° id_prop.csv: {e}")
                    print(f"  è¯·æ‰‹åŠ¨ç§»é™¤è¿™äº›ID")
            else:
                print(f"  âš ï¸  æœªæ‰¾åˆ° id_prop.csv")

    else:
        print("\nğŸ‰ æ‰€æœ‰ CIF æ–‡ä»¶éƒ½å¯ä»¥æ­£å¸¸è¯»å–ï¼")

    # æœ€ç»ˆç»Ÿè®¡
    remaining_cif = glob.glob(os.path.join(data_dir, "*.cif"))

    print("\n" + "=" * 70)
    print("æœ€ç»ˆç»Ÿè®¡")
    print("=" * 70)
    print(f"å¯ç”¨çš„ CIF æ–‡ä»¶: {len(remaining_cif)}")
    print(f"æ•°æ®ç›®å½•: {data_dir}")

    if os.path.exists(os.path.join(data_dir, "id_prop.csv")):
        try:
            df = pd.read_csv(os.path.join(data_dir, "id_prop.csv"))
            print(f"id_prop.csv è®°å½•æ•°: {len(df)}")
        except:
            pass

    print("\n" + "=" * 70)
    print("âœ… CIF æ–‡ä»¶æ£€æŸ¥å®Œæˆï¼")
    print("=" * 70)

    if len(bad_files) == 0 or action in ['move', 'delete']:
        print("\nç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒ:")
        print(f"  train_alignn.py --root_dir {data_dir} --config config_large_dataset.json \\")
        print(f"                  --classification_threshold 0.5 --batch_size 128 --epochs 100")

    return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å¤šçº¿ç¨‹æ£€æŸ¥ CIF æ–‡ä»¶å¯è¯»æ€§',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ•°ï¼ˆCPUæ ¸å¿ƒæ•°ï¼‰
  python check_cif_files_fast.py ./data/cif

  # æŒ‡å®š16ä¸ªçº¿ç¨‹
  python check_cif_files_fast.py ./data/cif --workers 16

  # è‡ªåŠ¨æ¨¡å¼ï¼ˆè‡ªåŠ¨ç§»åŠ¨é—®é¢˜æ–‡ä»¶ï¼‰
  python check_cif_files_fast.py ./data/cif --remove-bad --workers 32

  # è‡ªåŠ¨æ£€æµ‹æ•°æ®ç›®å½•
  python check_cif_files_fast.py --remove-bad
        """
    )

    parser.add_argument('data_dir', nargs='?', default=None,
                       help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--workers', '-w', type=int, default=None,
                       help=f'çº¿ç¨‹æ•° (é»˜è®¤: CPUæ ¸å¿ƒæ•° = {cpu_count()})')
    parser.add_argument('--remove-bad', action='store_true',
                       help='è‡ªåŠ¨ç§»åŠ¨æ— æ³•è¯»å–çš„æ–‡ä»¶åˆ°å•ç‹¬ç›®å½•')

    args = parser.parse_args()

    # ç¡®å®šæ•°æ®ç›®å½•
    if args.data_dir:
        data_dir = args.data_dir
    else:
        # è‡ªåŠ¨æ£€æµ‹
        if os.path.exists("./data/cif"):
            data_dir = "./data/cif"
        elif os.path.exists("./data"):
            data_dir = "./data"
        else:
            print("é”™è¯¯: è¯·æŒ‡å®šæ•°æ®ç›®å½•")
            print("ç”¨æ³•: python check_cif_files_fast.py <data_directory>")
            print("æˆ–å°†æ•°æ®æ”¾åœ¨ ./data æˆ– ./data/cif ç›®å½•ä¸‹")
            sys.exit(1)

    if not os.path.exists(data_dir):
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        sys.exit(1)

    # æ˜¾ç¤ºæ€§èƒ½æç¤º
    num_workers = args.workers if args.workers else cpu_count()
    print(f"\nğŸ’¡ æ€§èƒ½æç¤º:")
    print(f"   - CPU æ ¸å¿ƒæ•°: {cpu_count()}")
    print(f"   - ä½¿ç”¨çº¿ç¨‹æ•°: {num_workers}")
    print(f"   - é¢„è®¡é€Ÿåº¦æå‡: {num_workers}x (ç›¸æ¯”å•çº¿ç¨‹)")
    print(f"   - å¯¹äº 100k+ æ–‡ä»¶ï¼Œé¢„è®¡è€—æ—¶: {int(15 / num_workers * 10)} åˆ†é’Ÿ\n")

    success = check_cif_files_parallel(data_dir,
                                       num_workers=args.workers,
                                       remove_bad=args.remove_bad)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
