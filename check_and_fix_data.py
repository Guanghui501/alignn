#!/usr/bin/env python
"""
æ£€æŸ¥å’Œä¿®å¤ALIGNNæ•°æ®æ ¼å¼
"""
import os
import sys
import glob
import pandas as pd
from pathlib import Path

def check_and_fix_data(data_dir):
    """æ£€æŸ¥å¹¶ä¿®å¤æ•°æ®æ ¼å¼"""

    print("=" * 60)
    print("ALIGNN æ•°æ®æ ¼å¼æ£€æŸ¥å’Œä¿®å¤å·¥å…·")
    print("=" * 60)
    print(f"\næ•°æ®ç›®å½•: {data_dir}\n")

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False

    # æ£€æŸ¥id_prop.csv
    csv_path = os.path.join(data_dir, "id_prop.csv")
    if not os.path.exists(csv_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° id_prop.csv")
        return False

    print("ğŸ“„ æ£€æŸ¥ id_prop.csv...")

    # è¯»å–CSV
    try:
        # å…ˆçœ‹çœ‹åŸå§‹å†…å®¹
        with open(csv_path, 'r') as f:
            first_lines = [f.readline().strip() for _ in range(5)]

        print(f"\nå½“å‰æ–‡ä»¶å‰5è¡Œ:")
        for i, line in enumerate(first_lines, 1):
            print(f"  {i}. {line}")

        # å°è¯•è¯»å–
        df = pd.read_csv(csv_path, header=None)

        # æ£€æŸ¥æ ¼å¼
        has_header = False
        if df.iloc[0, 0] == 'id' or 'id' in str(df.iloc[0, 0]).lower():
            has_header = True
            df = pd.read_csv(csv_path)
        else:
            # æ²¡æœ‰headerï¼Œæ·»åŠ åˆ—å
            if df.shape[1] == 2:
                df.columns = ['id', 'target']
            else:
                print(f"âŒ é”™è¯¯: CSVæ–‡ä»¶åº”è¯¥æœ‰2åˆ—ï¼Œä½†æœ‰{df.shape[1]}åˆ—")
                return False

        print(f"\nâœ“ CSVæ–‡ä»¶åŒ…å« {len(df)} è¡Œæ•°æ®")
        print(f"âœ“ åˆ—å: {list(df.columns)}")

        # æ£€æŸ¥idåˆ—æ˜¯å¦åŒ…å«.cifåç¼€
        needs_fixing = False
        if df.iloc[0, 0].endswith('.cif'):
            print("\nâš ï¸  è­¦å‘Š: IDåˆ—åŒ…å« .cif åç¼€")
            needs_fixing = True

        # æ£€æŸ¥æ˜¯å¦æœ‰header
        if not has_header:
            print("âš ï¸  è­¦å‘Š: ç¼ºå°‘åˆ—åheader")
            needs_fixing = True

        if needs_fixing:
            print("\nğŸ”§ ä¿®å¤ id_prop.csv...")

            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = csv_path + ".backup"
            import shutil
            shutil.copy(csv_path, backup_path)
            print(f"   å¤‡ä»½åŸæ–‡ä»¶åˆ°: {backup_path}")

            # ä¿®å¤IDåˆ—ï¼ˆå»æ‰.cifåç¼€ï¼‰
            if df.columns[0] in ['id', '0'] or 'id' in str(df.columns[0]).lower():
                id_col = df.columns[0]
                df[id_col] = df[id_col].apply(lambda x: str(x).replace('.cif', ''))

            # ç¡®ä¿æœ‰æ­£ç¡®çš„åˆ—å
            df.columns = ['id', 'target']

            # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
            df.to_csv(csv_path, index=False)
            print(f"   âœ“ å·²ä¿®å¤ id_prop.csv")

            # æ˜¾ç¤ºä¿®å¤åçš„å†…å®¹
            print(f"\nä¿®å¤åçš„å‰5è¡Œ:")
            print(df.head())
        else:
            print("\nâœ“ id_prop.csv æ ¼å¼æ­£ç¡®")
            print(f"\nå‰5è¡Œæ•°æ®:")
            print(df.head())

    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

    # æ£€æŸ¥CIFæ–‡ä»¶
    print(f"\nğŸ“ æ£€æŸ¥CIFæ–‡ä»¶...")

    cif_files = glob.glob(os.path.join(data_dir, "*.cif"))
    print(f"   æ‰¾åˆ° {len(cif_files)} ä¸ª .cif æ–‡ä»¶")

    if len(cif_files) == 0:
        print("\nâš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°CIFæ–‡ä»¶ï¼")
        print(f"   è¯·ç¡®ä¿CIFæ–‡ä»¶åœ¨ç›®å½•: {data_dir}")
        print(f"\n   æ­£åœ¨æœç´¢å­ç›®å½•...")

        # æœç´¢å­ç›®å½•
        all_cif = glob.glob(os.path.join(data_dir, "**/*.cif"), recursive=True)
        if len(all_cif) > 0:
            print(f"\n   åœ¨å­ç›®å½•ä¸­æ‰¾åˆ° {len(all_cif)} ä¸ªCIFæ–‡ä»¶:")
            # ç»Ÿè®¡æ¯ä¸ªå­ç›®å½•çš„æ–‡ä»¶æ•°
            subdirs = {}
            for f in all_cif[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                subdir = os.path.dirname(f)
                subdirs[subdir] = subdirs.get(subdir, 0) + 1
                print(f"     - {f}")

            if len(all_cif) > 10:
                print(f"     ... è¿˜æœ‰ {len(all_cif) - 10} ä¸ªæ–‡ä»¶")

            print(f"\n   ğŸ’¡ å»ºè®®: å°†æ‰€æœ‰CIFæ–‡ä»¶ç§»åŠ¨åˆ° {data_dir} ç›®å½•")

            # è¯¢é—®æ˜¯å¦ç§»åŠ¨æ–‡ä»¶
            response = input("\næ˜¯å¦å°†CIFæ–‡ä»¶ç§»åŠ¨åˆ°æ•°æ®ç›®å½•? (y/n): ")
            if response.lower() == 'y':
                import shutil
                for cif_file in all_cif:
                    filename = os.path.basename(cif_file)
                    dest = os.path.join(data_dir, filename)
                    if not os.path.exists(dest):
                        shutil.copy(cif_file, dest)
                        print(f"   å¤åˆ¶: {filename}")

                cif_files = glob.glob(os.path.join(data_dir, "*.cif"))
                print(f"\n   âœ“ å·²å¤åˆ¶ {len(cif_files)} ä¸ªæ–‡ä»¶")
        else:
            print(f"\n   âŒ åœ¨æ•´ä¸ªç›®å½•æ ‘ä¸­éƒ½æ²¡æœ‰æ‰¾åˆ°CIFæ–‡ä»¶")
            return False
    else:
        print(f"   âœ“ CIFæ–‡ä»¶ç¤ºä¾‹:")
        for f in cif_files[:5]:
            print(f"     - {os.path.basename(f)}")
        if len(cif_files) > 5:
            print(f"     ... è¿˜æœ‰ {len(cif_files) - 5} ä¸ªæ–‡ä»¶")

    # æ£€æŸ¥id_prop.csvä¸­çš„IDæ˜¯å¦éƒ½æœ‰å¯¹åº”çš„CIFæ–‡ä»¶
    print(f"\nğŸ” æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")

    cif_basenames = {os.path.splitext(os.path.basename(f))[0] for f in cif_files}

    missing_files = []
    for idx, row in df.iterrows():
        file_id = str(row['id'])
        if file_id not in cif_basenames:
            missing_files.append(file_id)

    if missing_files:
        print(f"\nâš ï¸  è­¦å‘Š: {len(missing_files)} ä¸ªIDåœ¨id_prop.csvä¸­ä½†æ‰¾ä¸åˆ°å¯¹åº”çš„CIFæ–‡ä»¶:")
        for fid in missing_files[:10]:
            print(f"     - {fid}.cif (ç¼ºå¤±)")
        if len(missing_files) > 10:
            print(f"     ... è¿˜æœ‰ {len(missing_files) - 10} ä¸ªç¼ºå¤±")
    else:
        print(f"   âœ“ æ‰€æœ‰IDéƒ½æœ‰å¯¹åº”çš„CIFæ–‡ä»¶")

    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print("=" * 60)
    print(f"æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"CIFæ–‡ä»¶æ•°: {len(cif_files)}")
    print(f"ç¼ºå¤±æ–‡ä»¶: {len(missing_files)}")
    print(f"\nç›®æ ‡å€¼ç»Ÿè®¡:")
    print(df['target'].describe())

    # åˆ†ç±»é˜ˆå€¼å»ºè®®
    print(f"\nğŸ’¡ åˆ†ç±»é˜ˆå€¼å»ºè®®:")
    median = df['target'].median()
    mean = df['target'].mean()
    print(f"   - ä¸­ä½æ•°: {median:.4f}")
    print(f"   - å¹³å‡å€¼: {mean:.4f}")

    for threshold in [0.5, median, mean]:
        class_0 = (df['target'] <= threshold).sum()
        class_1 = (df['target'] > threshold).sum()
        print(f"\n   é˜ˆå€¼ {threshold:.4f}:")
        print(f"     ç±»åˆ«0 (â‰¤ {threshold:.4f}): {class_0} ({class_0/len(df)*100:.1f}%)")
        print(f"     ç±»åˆ«1 (> {threshold:.4f}): {class_1} ({class_1/len(df)*100:.1f}%)")

    print(f"\n" + "=" * 60)
    print("âœ… æ•°æ®æ£€æŸ¥å®Œæˆï¼")
    print("=" * 60)

    if len(missing_files) == 0 and len(cif_files) > 0:
        print("\nğŸ‰ æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")
        return True
    else:
        print("\nâš ï¸  è¯·ä¿®å¤ä¸Šè¿°é—®é¢˜åå†å¼€å§‹è®­ç»ƒ")
        return False


if __name__ == "__main__":
    if len(sys.argv) > 1:
        data_dir = sys.argv[1]
    else:
        data_dir = "./data"

    success = check_and_fix_data(data_dir)

    if success:
        print("\nä¸‹ä¸€æ­¥: è¿è¡Œè®­ç»ƒè„šæœ¬")
        print("  ./run_binary_classification.sh")

    sys.exit(0 if success else 1)
