# ALIGNN äºŒåˆ†ç±» - å¿«é€Ÿå¼€å§‹æŒ‡å—

## âœ… å·²ä¿®å¤çš„é—®é¢˜

1. âœ… pydantic ä¾èµ–é—®é¢˜
2. âœ… id_prop.csv æ ¼å¼é—®é¢˜ï¼ˆè‡ªåŠ¨ç§»é™¤ .cif åç¼€ï¼Œæ·»åŠ  headerï¼‰
3. âœ… é…ç½®æ–‡ä»¶å‚æ•°é”™è¯¯ï¼ˆç§»é™¤ä¸æ”¯æŒçš„ num_heads, attention_headsï¼‰
4. âœ… CIF æ–‡ä»¶æœç´¢å’Œå®šä½

## ğŸ“‹ å‡†å¤‡å·¥ä½œ

### 1. æ•°æ®æ ¼å¼è¦æ±‚

**ç›®å½•ç»“æ„:**
```
your_dataset/
â”œâ”€â”€ id_prop.csv
â”œâ”€â”€ 0.cif
â”œâ”€â”€ 1.cif
â”œâ”€â”€ 2.cif
â””â”€â”€ ...
```

**id_prop.csv æ ¼å¼:**
```csv
id,target
0,1
1,0
2,1
3,0
```

### 2. ç¯å¢ƒè¦æ±‚
- Python 3.8-3.11
- PyTorch + DGL
- ALIGNN å·²å®‰è£…

## ğŸš€ ä¸‰æ­¥å¼€å§‹è®­ç»ƒ

### æ–¹æ³•ä¸€ï¼šä¸€é”®è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
# 1. ä¿®æ”¹é…ç½®ï¼ˆåªéœ€æ”¹è¿™ä¸¤è¡Œï¼‰
nano run_binary_classification.sh
# DATA_DIR="./data"           # æ”¹ä¸ºæ‚¨çš„æ•°æ®ç›®å½•
# THRESHOLD=0.5               # æ”¹ä¸ºåˆé€‚çš„é˜ˆå€¼

# 2. è¿è¡Œè®­ç»ƒ
./run_binary_classification.sh
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨ Python è„šæœ¬

```bash
# 1. ä¿®æ”¹é…ç½®
nano train_binary_classification_example.py
# ROOT_DIR = "./your_dataset"
# CLASSIFICATION_THRESHOLD = 0.5

# 2. è¿è¡Œè®­ç»ƒ
python train_binary_classification_example.py
```

### æ–¹æ³•ä¸‰ï¼šå‘½ä»¤è¡Œç›´æ¥è¿è¡Œ

```bash
train_alignn.py \
    --root_dir ./data \
    --config config_binary_classification.json \
    --classification_threshold 0.5 \
    --file_format cif \
    --batch_size 128 \
    --epochs 300 \
    --output_dir ./results
```

## ğŸ“Š æ ¹æ®æ•°æ®é›†å¤§å°é€‰æ‹©é…ç½®

### å°æ•°æ®é›†ï¼ˆ< 1000 æ ·æœ¬ï¼‰
```bash
train_alignn.py \
    --root_dir ./data \
    --config config_small_dataset.json \
    --output_dir ./results
```

**ç‰¹ç‚¹:**
- æ›´å¤šè®­ç»ƒè½®æ•° (500)
- æ›´å°æ‰¹æ¬¡ (16)
- æ›´å°æ¨¡å‹ (hidden=128, layers=3)
- é˜²æ­¢è¿‡æ‹Ÿåˆ

### ä¸­ç­‰æ•°æ®é›†ï¼ˆ1000-10000 æ ·æœ¬ï¼‰
```bash
train_alignn.py \
    --root_dir ./data \
    --config config_binary_classification.json \
    --output_dir ./results
```

**ç‰¹ç‚¹:**
- æ ‡å‡†é…ç½® (epochs=300)
- é€‚ä¸­æ‰¹æ¬¡ (32)
- æ ‡å‡†æ¨¡å‹ (hidden=256, layers=4)

### å¤§æ•°æ®é›†ï¼ˆ> 10000 æ ·æœ¬ï¼Œå¦‚æ‚¨çš„108134æ ·æœ¬ï¼‰
```bash
train_alignn.py \
    --root_dir ./data \
    --config config_large_dataset.json \
    --output_dir ./results
```

**ç‰¹ç‚¹:**
- è¾ƒå°‘è½®æ•° (100)
- å¤§æ‰¹æ¬¡ (128)
- å¤§æ¨¡å‹ (hidden=512, layers=6)
- æ›´å¿«è®­ç»ƒ

## ğŸ”§ å¸¸è§è°ƒæ•´

### è°ƒæ•´åˆ†ç±»é˜ˆå€¼

æ‚¨çš„æ•°æ®é›†æœ‰ 108134 ä¸ªæ ·æœ¬ï¼Œå»ºè®®å…ˆåˆ†ææ•°æ®åˆ†å¸ƒï¼š

```python
import pandas as pd
df = pd.read_csv('./data/id_prop.csv')

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
print(df['target'].describe())

# æŸ¥çœ‹ä¸åŒé˜ˆå€¼çš„åˆ†å¸ƒ
for threshold in [0.3, 0.5, 0.7, df['target'].median()]:
    class_0 = (df['target'] <= threshold).sum()
    class_1 = (df['target'] > threshold).sum()
    print(f"\né˜ˆå€¼ {threshold:.2f}:")
    print(f"  ç±»åˆ«0: {class_0} ({class_0/len(df)*100:.1f}%)")
    print(f"  ç±»åˆ«1: {class_1} ({class_1/len(df)*100:.1f}%)")
```

ç„¶ååœ¨é…ç½®æ–‡ä»¶æˆ–å‘½ä»¤è¡Œä¸­è®¾ç½®åˆé€‚çš„é˜ˆå€¼ã€‚

### è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼ˆGPUå†…å­˜ï¼‰

```bash
# GPU å†…å­˜ä¸è¶³æ—¶å‡å°æ‰¹æ¬¡
--batch_size 32   # æˆ– 16

# GPU å†…å­˜å……è¶³æ—¶å¢å¤§æ‰¹æ¬¡ï¼ˆè®­ç»ƒæ›´å¿«ï¼‰
--batch_size 256  # æˆ– 512
```

### è°ƒæ•´è®­ç»ƒè½®æ•°

```bash
# å¿«é€Ÿæµ‹è¯•
--epochs 10

# æ ‡å‡†è®­ç»ƒ
--epochs 300

# å……åˆ†è®­ç»ƒï¼ˆå°æ•°æ®é›†ï¼‰
--epochs 500
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿›åº¦

è®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºï¼š
```
Epoch 1/300
  Train Loss: 0.523 | Time: 125s
  Val Loss: 0.487 | Time: 12s
  âœ“ Saving model

Epoch 2/300
  Train Loss: 0.412 | Time: 123s
  Val Loss: 0.398 | Time: 11s
  âœ“ Saving model

...
```

## ğŸ“ è®­ç»ƒç»“æœ

è®­ç»ƒå®ŒæˆåæŸ¥çœ‹ç»“æœï¼š

```bash
# æŸ¥çœ‹æµ‹è¯•é›†é¢„æµ‹ç»“æœ
head -20 ./results/prediction_results_test_set.csv

# æŸ¥çœ‹è®­ç»ƒå†å²
cat ./results/history_train.json | python -m json.tool

# ä½¿ç”¨æœ€ä½³æ¨¡å‹
ls -lh ./results/best_model.pt
```

## ğŸ¯ ä¼˜åŒ–å»ºè®®

### å¦‚æœè¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒæŸå¤±ä½ä½†éªŒè¯æŸå¤±é«˜ï¼‰
1. å‡å°æ¨¡å‹: `hidden_features: 128`, `layers: 3`
2. å¢åŠ æ­£åˆ™åŒ–: `weight_decay: 1e-5`
3. å¢åŠ è®­ç»ƒæ•°æ®
4. ä½¿ç”¨ early stopping

### å¦‚æœæ¬ æ‹Ÿåˆï¼ˆè®­ç»ƒå’ŒéªŒè¯æŸå¤±éƒ½å¾ˆé«˜ï¼‰
1. å¢å¤§æ¨¡å‹: `hidden_features: 512`, `layers: 6`
2. å¢åŠ è®­ç»ƒè½®æ•°: `epochs: 500`
3. è°ƒæ•´å­¦ä¹ ç‡: å°è¯• `0.001` æˆ– `0.01`
4. æ£€æŸ¥æ•°æ®è´¨é‡

### å¦‚æœè®­ç»ƒå¤ªæ…¢
1. å¢å¤§æ‰¹æ¬¡: `batch_size: 256`
2. å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹: `num_workers: 8`
3. å‡å°æ¨¡å‹å¤§å°
4. ä½¿ç”¨ LMDB ç¼“å­˜: `use_lmdb: true`

## ğŸ› æ•…éšœæ’é™¤

### é”™è¯¯: "No such file or directory"
```bash
# æ£€æŸ¥æ•°æ®
python check_and_fix_data.py ./data
```

### é”™è¯¯: "Extra inputs are not permitted"
**å·²ä¿®å¤ï¼** æ–°çš„é…ç½®æ–‡ä»¶å·²ç»ç§»é™¤äº†ä¸æ”¯æŒçš„å‚æ•°ã€‚

### é”™è¯¯: "Out of memory"
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
--batch_size 16

# æˆ–ä½¿ç”¨å°æ¨¡å‹é…ç½®
--config config_small_dataset.json
```

### é”™è¯¯: "pydantic._internal"
```bash
# è¿è¡Œä¿®å¤è„šæœ¬
./fix_dependencies.sh
```

## ğŸ“š æ›´å¤šèµ„æº

- **äºŒåˆ†ç±»è®­ç»ƒæŒ‡å—.md** - è¯¦ç»†çš„è®­ç»ƒæ­¥éª¤å’Œå‚æ•°è¯´æ˜
- **é…ç½®å‚æ•°è¯¦è§£.md** - æ‰€æœ‰é…ç½®å‚æ•°çš„è¯¦ç»†è¯´æ˜
- **é—®é¢˜ä¿®å¤æŒ‡å—.md** - å¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ

## ğŸ’¡ æ¨èå·¥ä½œæµç¨‹

```bash
# 1. æ£€æŸ¥å’Œä¿®å¤æ•°æ®ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
python check_and_fix_data.py ./data

# 2. æ ¹æ®æ•°æ®é›†å¤§å°é€‰æ‹©é…ç½®
# å°æ•°æ®é›†: config_small_dataset.json
# ä¸­ç­‰æ•°æ®é›†: config_binary_classification.json
# å¤§æ•°æ®é›†: config_large_dataset.json (æ¨èï¼Œå› ä¸ºæ‚¨æœ‰108134æ ·æœ¬)

# 3. å¿«é€Ÿæµ‹è¯•ï¼ˆ10è½®ç¡®è®¤èƒ½è¿è¡Œï¼‰
train_alignn.py \
    --root_dir ./data \
    --config config_large_dataset.json \
    --epochs 10 \
    --output_dir ./test_results

# 4. æ­£å¼è®­ç»ƒ
train_alignn.py \
    --root_dir ./data \
    --config config_large_dataset.json \
    --output_dir ./results

# 5. è¯„ä¼°ç»“æœ
cat ./results/prediction_results_test_set.csv | head -20
```

## âš¡ æ‚¨çš„æ•°æ®é›†ç‰¹ç‚¹

- âœ… 108134 ä¸ª CIF æ–‡ä»¶ - **å¤§æ•°æ®é›†**
- âœ… æ•°æ®æ ¼å¼æ­£ç¡®
- ğŸ’¡ å»ºè®®ä½¿ç”¨ `config_large_dataset.json`
- ğŸ’¡ å»ºè®®æ‰¹æ¬¡å¤§å°: 128-256
- ğŸ’¡ å»ºè®®è®­ç»ƒè½®æ•°: 50-100ï¼ˆæ•°æ®é‡å¤§ï¼Œä¸éœ€è¦å¤ªå¤šè½®ï¼‰

## ğŸŠ å¼€å§‹è®­ç»ƒ

```bash
# æ¨èå‘½ä»¤ï¼ˆé€‚åˆæ‚¨çš„108Kæ•°æ®é›†ï¼‰
train_alignn.py \
    --root_dir ./data \
    --config config_large_dataset.json \
    --classification_threshold 0.5 \
    --batch_size 128 \
    --epochs 100 \
    --output_dir ./results_108k

# é¢„è®¡è®­ç»ƒæ—¶é—´ï¼šæ ¹æ®GPUæ€§èƒ½
# V100: ~10-20å°æ—¶
# A100: ~5-10å°æ—¶
# RTX 3090: ~15-30å°æ—¶
```

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
